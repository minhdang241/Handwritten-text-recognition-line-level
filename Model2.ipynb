{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1206 10:19:38.435710 140266919671616 __init__.py:329] Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "W1206 10:19:38.445597 140266919671616 __init__.py:329] Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "W1206 10:19:38.446630 140266919671616 __init__.py:329] Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "W1206 10:19:38.461788 140266919671616 __init__.py:357] Limited tf.summary API due to missing TensorBoard installation.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get labels + filenames\n",
    "chars = set()\n",
    "labels = []\n",
    "files = []\n",
    "bad_samples = []\n",
    "data_root_path = Path(\"../data2\")\n",
    "for line in open(data_root_path/\"sentences.txt\").read().splitlines():\n",
    "    if line[0] == \"#\":\n",
    "        continue\n",
    "    tokens = line.split(\" \")\n",
    "    assert len(tokens) > 9\n",
    "    # Get file names\n",
    "    filename_token = tokens[0].split(\"-\")\n",
    "    file_path = data_root_path/f'{filename_token[0]}/{filename_token[0] + \"-\" + filename_token[1]}/{tokens[0]}.png'  \n",
    "    if not os.path.getsize(file_path):\n",
    "        bad_samples.append(file_path)\n",
    "        continue\n",
    "    label = \" \".join(\" \".join(tokens[9:]).split(\"|\"))\n",
    "    labels.append(label)\n",
    "    chars = chars.union(set(list(label)))\n",
    "    files.append(str(file_path))\n",
    "    assert len(files) == len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(path, label):\n",
    "    plt.title(label, fontsize=12)\n",
    "    plt.imshow(cv2.imread(path, cv2.IMREAD_GRAYSCALE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_image(files[0], labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def preprocess(img, imgSize, dataAugmentation=False):\n",
    "    \"put img into target img of size imgSize, transpose for TF and normalize gray-values\"\n",
    "    \n",
    "    # there are damaged files in IAM dataset - just use black image instead\n",
    "    if img is None:\n",
    "        img = np.zeros([imgSize[1], imgSize[0]])\n",
    "    \n",
    "    # increase dataset size by applying random stretches to the images\n",
    "    if dataAugmentation:\n",
    "        stretch = (random.random() - 0.5) # -0.5 .. +0.5\n",
    "        wStretched = max(int(img.shape[1] * (1 + stretch)), 1) # random width, but at least 1\n",
    "        img = cv2.resize(img, (wStretched, img.shape[0])) # stretch horizontally by factor 0.5 .. 1.5\n",
    "    \n",
    "    # create target image and copy sample image into it\n",
    "    (wt, ht) = imgSize\n",
    "    (h, w) = img.shape\n",
    "    fx = w / wt\n",
    "    fy = h / ht\n",
    "    f = max(fx, fy)\n",
    "    newSize = (max(min(wt, int(w / f)), 1), max(min(ht, int(h / f)), 1)) # scale according to f (result at least 1 and at most wt or ht)\n",
    "    img = cv2.resize(img, newSize)\n",
    "    target = np.ones([ht, wt]) * 255\n",
    "    target[0:newSize[1], 0:newSize[0]] = img\n",
    "    \n",
    "    # transpose for TF\n",
    "    img = target\n",
    "    \n",
    "    # normalize\n",
    "    #(m, s) = cv2.meanStdDev(img)\n",
    "    #m = m[0][0]\n",
    "    #s = s[0][0]\n",
    "    #img = img - m\n",
    "    #img = img / s if s>0 else img\n",
    "    img = img/255\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process data for learning task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "length = math.floor(0.9*len(files))\n",
    "idxs = np.arange(0, len(files))\n",
    "rand_idxs = tf.random.shuffle(idxs, seed=42).numpy()\n",
    "train_idxs = rand_idxs[:length]\n",
    "test_idxs = rand_idxs[length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = np.array([files[f] for f in train_idxs])\n",
    "test_files = np.array([files[f] for f in test_idxs])\n",
    "\n",
    "assert len(train_files) + len(test_files) == len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['../data2/a01/a01-091/a01-091-s03-00.png',\n",
       "       '../data2/c03/c03-016c/c03-016c-s01-02.png',\n",
       "       '../data2/j04/j04-039/j04-039-s01-06.png', ...,\n",
       "       '../data2/p03/p03-121/p03-121-s06-01.png',\n",
       "       '../data2/h07/h07-020/h07-020-s00-01.png',\n",
       "       '../data2/g07/g07-003b/g07-003b-s00-02.png'], dtype='<U41')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(chars)\n",
    "char2idx = {u:i for i,u in enumerate(chars)}\n",
    "idx2char = np.array(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_to_labels(txt):\n",
    "    encoded = []\n",
    "    for c in txt:\n",
    "        encoded.append(char2idx[c])\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_text_length = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = []\n",
    "train_input_lengths = []\n",
    "train_label_lengths = []\n",
    "orig_txt = []\n",
    "train_txt = []\n",
    "for i in train_idxs:\n",
    "    train_images.append(np.expand_dims(preprocess(cv2.imread(files[i], cv2.IMREAD_GRAYSCALE), imgSize=(512,32),dataAugmentation=True), axis=-1))\n",
    "    train_input_lengths.append(127)\n",
    "    train_label_lengths.append(len(labels[i]))\n",
    "    if len(labels[i]) > max_text_length: max_text_length = len(labels[i])\n",
    "    train_txt.append(encode_to_labels(labels[i]))\n",
    "    orig_txt.append(labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = []\n",
    "test_input_lengths = []\n",
    "test_label_lengths = []\n",
    "test_txt = []\n",
    "test_orig_txt = []\n",
    "for i in test_idxs:\n",
    "    test_images.append(np.expand_dims(preprocess(cv2.imread(files[i], cv2.IMREAD_GRAYSCALE), imgSize=(512,32)), axis=-1))\n",
    "    test_input_lengths.append(127)\n",
    "    test_label_lengths.append(len(labels[i]))\n",
    "    if len(labels[i]) > max_text_length: max_text_length = len(labels[i])\n",
    "    test_txt.append(encode_to_labels(labels[i]))\n",
    "    test_orig_txt.append(labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_padded_txt = pad_sequences(train_txt, maxlen=max_text_length, padding='post', value=len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_padded_txt = pad_sequences(test_txt, maxlen=max_text_length, padding='post', value=len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ',\n",
       " '!',\n",
       " '\"',\n",
       " '#',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ':',\n",
       " ';',\n",
       " '?',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape=(32, 512, 1))\n",
    "conv_1 = layers.Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu', name='conv1')(inputs)\n",
    "pool_1 = layers.MaxPool2D(pool_size=(2,2), name='pool1')(conv_1)\n",
    "conv_2 = layers.Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu', name='conv2')(pool_1)\n",
    "pool_2 = layers.MaxPool2D(pool_size=(2,2), name='pool2')(conv_2)\n",
    "conv_3 = layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu', name='conv3')(pool_2)\n",
    "batch_1 = layers.BatchNormalization(name='batch1')(conv_3)\n",
    "conv_4 = layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu', name='conv4')(batch_1)\n",
    "pool_3 = layers.MaxPool2D(pool_size=(2,1), name='pool3')(conv_4)\n",
    "conv_5 = layers.Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu', name='conv5')(pool_3)\n",
    "batch_2 = layers.BatchNormalization(name='batch2')(conv_5)\n",
    "conv_6 = layers.Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu', name='conv6')(batch_2)\n",
    "pool_4 = layers.MaxPool2D(pool_size=(2,1), name='pool4')(conv_6)\n",
    "conv_7 = layers.Conv2D(filters=512, kernel_size=(2,2), strides=(1,1), padding='valid', activation='relu', name='conv7')(pool_4)\n",
    "squeezed = layers.Lambda(lambda x: tf.squeeze(x, axis=1))(conv_7)\n",
    "blstm_1 = layers.Bidirectional(layers.LSTM(128, return_sequences=True), name='blstm_1')(squeezed)\n",
    "blstm_2 = layers.Bidirectional(layers.LSTM(128, return_sequences=True), name='blstm_2')(blstm_1)\n",
    "outputs = layers.Dense(80, activation = 'softmax')(blstm_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 512, 1)]      0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 32, 512, 64)       640       \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 16, 256, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 16, 256, 128)      73856     \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 8, 128, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 8, 128, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch1 (BatchNormalization)  (None, 8, 128, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 8, 128, 256)       590080    \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling2D)         (None, 4, 128, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv5 (Conv2D)               (None, 4, 128, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "batch2 (BatchNormalization)  (None, 4, 128, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv6 (Conv2D)               (None, 4, 128, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling2D)         (None, 2, 128, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv7 (Conv2D)               (None, 1, 127, 512)       1049088   \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 127, 512)          0         \n",
      "_________________________________________________________________\n",
      "blstm_1 (Bidirectional)      (None, 127, 256)          656384    \n",
      "_________________________________________________________________\n",
      "blstm_2 (Bidirectional)      (None, 127, 256)          394240    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 127, 80)           20560     \n",
      "=================================================================\n",
      "Total params: 6,623,056\n",
      "Trainable params: 6,621,520\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "act_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = layers.Input(name='the_labels', shape=[max_text_length], dtype='float32')\n",
    "input_length = layers.Input(name='input_length', shape=[1], dtype='int64')\n",
    "label_length = layers.Input(name='label_length', shape=[1], dtype='int64')\n",
    "\n",
    "\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "\n",
    "    return tf.keras.backend.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "\n",
    "loss_out = layers.Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([outputs, labels, input_length, label_length])\n",
    "model = tf.keras.Model(inputs=[inputs, labels, input_length, label_length], outputs=loss_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 512, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 32, 512, 64)  640         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 16, 256, 64)  0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 16, 256, 128) 73856       pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool2 (MaxPooling2D)            (None, 8, 128, 128)  0           conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3 (Conv2D)                  (None, 8, 128, 256)  295168      pool2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch1 (BatchNormalization)     (None, 8, 128, 256)  1024        conv3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv4 (Conv2D)                  (None, 8, 128, 256)  590080      batch1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 4, 128, 256)  0           conv4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv5 (Conv2D)                  (None, 4, 128, 512)  1180160     pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch2 (BatchNormalization)     (None, 4, 128, 512)  2048        conv5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv6 (Conv2D)                  (None, 4, 128, 512)  2359808     batch2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "pool4 (MaxPooling2D)            (None, 2, 128, 512)  0           conv6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv7 (Conv2D)                  (None, 1, 127, 512)  1049088     pool4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 127, 512)     0           conv7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "blstm_1 (Bidirectional)         (None, 127, 256)     656384      lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "blstm_2 (Bidirectional)         (None, 127, 256)     394240      blstm_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 127, 80)      20560       blstm_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "the_labels (InputLayer)         [(None, 93)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_length (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "label_length (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ctc (Lambda)                    (None, 1)            0           dense[0][0]                      \n",
      "                                                                 the_labels[0][0]                 \n",
      "                                                                 input_length[0][0]               \n",
      "                                                                 label_length[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 6,623,056\n",
      "Trainable params: 6,621,520\n",
      "Non-trainable params: 1,536\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_img = np.array(train_images)\n",
    "train_input_length = np.array(train_input_lengths)\n",
    "train_label_length = np.array(train_label_lengths)\n",
    "\n",
    "valid_img = np.array(test_images)\n",
    "valid_input_length = np.array(test_input_lengths)\n",
    "valid_label_length = np.array(test_label_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"best_model_2.hdf5\"\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1206 11:12:37.007085 140266919671616 ag_logging.py:146] AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f901d42dcb0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f901d42dcb0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "20/20 [==============================] - ETA: 0s - loss: 778.4041"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1206 11:13:14.621090 140266919671616 ag_logging.py:146] AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f901d491a70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f901d491a70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 793.94135, saving model to best_model_2.hdf5\n",
      "20/20 [==============================] - 32s 2s/step - loss: 778.4041 - val_loss: 793.9413\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 778.4041\n",
      "Epoch 00002: val_loss did not improve from 793.94135\n",
      "20/20 [==============================] - 31s 2s/step - loss: 778.4041 - val_loss: 793.9413\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 778.4039\n",
      "Epoch 00003: val_loss did not improve from 793.94135\n",
      "20/20 [==============================] - 31s 2s/step - loss: 778.4039 - val_loss: 793.9413\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 778.4040\n",
      "Epoch 00004: val_loss did not improve from 793.94135\n",
      "20/20 [==============================] - 31s 2s/step - loss: 778.4040 - val_loss: 793.9413\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 778.4039\n",
      "Epoch 00005: val_loss did not improve from 793.94135\n",
      "20/20 [==============================] - 31s 2s/step - loss: 778.4039 - val_loss: 793.9413\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 778.4039\n",
      "Epoch 00006: val_loss did not improve from 793.94135\n",
      "20/20 [==============================] - 31s 2s/step - loss: 778.4039 - val_loss: 793.9413\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 778.4040\n",
      "Epoch 00007: val_loss did not improve from 793.94135\n",
      "20/20 [==============================] - 31s 2s/step - loss: 778.4040 - val_loss: 793.9413\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 778.4041\n",
      "Epoch 00008: val_loss did not improve from 793.94135\n",
      "20/20 [==============================] - 31s 2s/step - loss: 778.4041 - val_loss: 793.9413\n",
      "Epoch 9/100\n",
      "15/20 [=====================>........] - ETA: 7s - loss: 775.2883"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-c1a0e456b4ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtraining_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_padded_txt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_input_length\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label_length\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_padded_txt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_input_length\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_label_length\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x=[training_img[:5000], train_padded_txt[:5000], train_input_length[:5000], train_label_length[:5000]], y=np.zeros(len(training_img[:5000])), batch_size=256, epochs = 100, validation_data = ([valid_img[:100], test_padded_txt[:100], valid_input_length[:100], valid_label_length[:100]], [np.zeros(len(valid_img[:100]))]), verbose = 1, callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([66, 67, 72,  0, 62, 67, 61, 66,  0, 77, 67, 73,  0, 12,  0,  5, 79,\n",
       "       79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79,\n",
       "       79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79,\n",
       "       79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79,\n",
       "       79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79,\n",
       "       79, 79, 79, 79, 79, 79, 79, 79], dtype=int32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.squeeze(training_img[4999]))\n",
    "train_padded_txt[4999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_padded_txt[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 512, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 32, 512, 64)  640         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 16, 256, 64)  0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 16, 256, 128) 73856       pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool2 (MaxPooling2D)            (None, 8, 128, 128)  0           conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3 (Conv2D)                  (None, 8, 128, 256)  295168      pool2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch1 (BatchNormalization)     (None, 8, 128, 256)  1024        conv3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv4 (Conv2D)                  (None, 8, 128, 256)  590080      batch1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 4, 128, 256)  0           conv4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv5 (Conv2D)                  (None, 4, 128, 512)  1180160     pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch2 (BatchNormalization)     (None, 4, 128, 512)  2048        conv5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv6 (Conv2D)                  (None, 4, 128, 512)  2359808     batch2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "pool4 (MaxPooling2D)            (None, 2, 128, 512)  0           conv6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv7 (Conv2D)                  (None, 1, 127, 512)  1049088     pool4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 127, 512)     0           conv7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "blstm_1 (Bidirectional)         (None, 127, 256)     656384      lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "blstm_2 (Bidirectional)         (None, 127, 256)     394240      blstm_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 127, 80)      20560       blstm_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "the_label (InputLayer)          [(None, 93)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_length (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "label_length (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ctc (Lambda)                    (None, 1)            0           dense[0][0]                      \n",
      "                                                                 the_label[0][0]                  \n",
      "                                                                 input_length[0][0]               \n",
      "                                                                 label_length[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 6,623,056\n",
      "Trainable params: 6,621,520\n",
      "Non-trainable params: 1,536\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbs = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_img = np.array(test_images)\n",
    "valid_input_length = np.array(test_input_lengths)\n",
    "valid_label_length = np.array(test_label_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1676, 32, 512, 1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(valid_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_model.load_weights(\"best_model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = act_model.predict(training_img[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_batch(out):\n",
    "    ret = []\n",
    "    for j in range(out.shape[0]):\n",
    "        out_best = list(np.argmax(out[j, 2:], 1))\n",
    "        print(out_best)\n",
    "        out_best = [k for k, g in itertools.groupby(out_best)]\n",
    "        print(out_best)\n",
    "        outstr = \"\" if out_best[0] == 79 else idx2char[out_best]\n",
    "        ret.append(outstr)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79]\n",
      "[79]\n",
      "[79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79]\n",
      "[79]\n",
      "[79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79]\n",
      "[79]\n",
      "[79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79]\n",
      "[79]\n",
      "[79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79]\n",
      "[79]\n",
      "[79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79]\n",
      "[79]\n",
      "[79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79]\n",
      "[79]\n",
      "[79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79]\n",
      "[79]\n",
      "[79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79]\n",
      "[79]\n",
      "[79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79]\n",
      "[79]\n",
      "[79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79]\n",
      "[79]\n",
      "[79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79]\n",
      "[79]\n",
      "[79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79]\n",
      "[79]\n",
      "[79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79]\n",
      "[79]\n",
      "[79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79]\n",
      "[79]\n",
      "[79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79]\n",
      "[79]\n",
      "[79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79]\n",
      "[79]\n",
      "[79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79]\n",
      "[79]\n",
      "[79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79]\n",
      "[79]\n",
      "[79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79]\n",
      "[79]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "decode_batch(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1676, 32, 512, 1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = tf.keras.backend.get_value(tf.keras.backend.ctc_decode(prediction, input_length=np.ones(prediction.shape[0])*prediction.shape[1],\n",
    "                         greedy=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 127, 80)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<tf.Tensor: shape=(10, 0), dtype=int64, numpy=array([], shape=(10, 0), dtype=int64)>],\n",
       " <tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
       " array([[54.974827],\n",
       "        [54.975483],\n",
       "        [54.90303 ],\n",
       "        [55.049744],\n",
       "        [55.02597 ],\n",
       "        [54.894756],\n",
       "        [55.027332],\n",
       "        [54.999607],\n",
       "        [54.990856],\n",
       "        [54.898495]], dtype=float32)>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(prediction[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(valid_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_prediction = tf.transpose(prediction, perm=(1, 0, 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
